{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "2.Extract_Features.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyOxrhULi6kQKaXrEemcFwfp",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/imran1386khan/Biobert-Training-Google-Colab/blob/master/2_Extract_Features.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "11cSrPfBmSsO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip install tensorflow==2.0.0-alpha0"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jg4mxMlNpWJZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "import urllib.request\n",
        "\n",
        "#Link to pre-trained BERT\n",
        "urllib.request.urlretrieve('https://github.com/naver/biobert-pretrained/releases/download/v1.0-pubmed-pmc/biobert_v1.0_pubmed_pmc.tar.gz', 'BioBert.tar.gz')\n",
        "\n",
        "if not os.path.exists('BioBertFolder'):\n",
        "    os.makedirs('BioBertFolder')\n",
        "    \n",
        "import tarfile\n",
        "tar = tarfile.open(\"BioBert.tar.gz\")\n",
        "tar.extractall(path='BioBertFolder/')\n",
        "tar.close()\n",
        "\n",
        "!wget https://github.com/re-search/DocProduct/archive/v0.2.0_dev.zip\n",
        "!wget https://github.com/re-search/gpt2-estimator/archive/master.zip\n",
        "\n",
        "!unzip master.zip\n",
        "!unzip v0.2.0_dev.zip\n",
        "\n",
        "!mv DocProduct-0.2.0_dev/* /content/\n",
        "!mv gpt2-estimator-master/* /content/\n",
        "\n",
        "!wget  https://anaconda.org/pytorch/faiss-cpu/1.2.1/download/linux-64/faiss-cpu-1.2.1-py36_cuda9.0.176_1.tar.bz2\n",
        "\n",
        "!tar xvjf faiss-cpu-1.2.1-py36_cuda9.0.176_1.tar.bz2\n",
        "!cp -r lib/python3.6/site-packages/* /usr/local/lib/python3.6/dist-packages/\n",
        "!pip install mkl"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9CLaLCZfpdP0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import argparse\n",
        "import cv2\n",
        "import sys\n",
        "\n",
        "import tensorflow as tf\n",
        "# tf.compat.v1.enable_eager_execution()\n",
        "tf.compat.v1.disable_eager_execution()\n",
        "import tensorflow.keras.backend as K\n",
        "from tensorflow.keras.models import load_model\n",
        "import argparse\n",
        "import os\n",
        "import requests\n",
        "\n",
        "from docproduct.dataset import create_dataset_for_bert\n",
        "from docproduct.models import MedicalQAModelwithBert\n",
        "from docproduct.loss import qa_pair_loss, qa_pair_cross_entropy_loss\n",
        "from docproduct.tokenization import FullTokenizer\n",
        "from docproduct.metrics import qa_pair_batch_accuracy"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2rCLWaWDo1MY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import argparse\n",
        "import os\n",
        "from glob import glob\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "from docproduct.predictor import QAEmbed\n",
        "\n",
        "model_path='/content/drive/My Drive/DocAssistTraining/bertffn_crossentropy/bertffn/'\n",
        "data_path='/content/data/'\n",
        "output_path='/content/output.prkt'\n",
        "pretrained_path='/content/BioBertFolder/biobert_v1.0_pubmed_pmc/'\n",
        "\n",
        "!mkdir '/content/data'\n",
        "!cp '/content/drive/My Drive/data/QandA_Dataset.csv' '/content/data/train_data.csv'\n",
        "\n",
        "def read_all(data_path):\n",
        "    glob_pattern = os.path.join(data_path, '*.csv')\n",
        "    df_list = []\n",
        "    for f in glob(glob_pattern):\n",
        "        print('Reading {0}'.format(f))\n",
        "        if os.path.basename(f) == 'healthtap_data_cleaned.csv':\n",
        "            df = pd.read_csv(f, lineterminator='\\n')\n",
        "            df.columns = ['index', 'question', 'answer']\n",
        "            df.drop(columns=['index'], inplace=True)\n",
        "        else:\n",
        "            df = pd.read_csv(f, encoding='utf8', lineterminator='\\n')\n",
        "        try:\n",
        "            df.drop(columns=['question_bert', 'answer_bert'], inplace=True)\n",
        "        except:\n",
        "            pass\n",
        "        df_list.append(df)\n",
        "    return pd.concat(df_list, axis=0)\n",
        "\n",
        "\n",
        "def train_data_to_embedding(model_path='models/bertffn_crossentropy/bertffn',\n",
        "                            data_path='data/mqa_csv',\n",
        "                            output_path='qa_embeddings/bertffn_crossentropy.zip',\n",
        "                            pretrained_path='models/pubmed_pmc_470k/'):\n",
        "    \"\"\"Function to generate similarity embeddings for QA pairs.\n",
        "\n",
        "    Input file format:\n",
        "        question,answer\n",
        "        my eyes hurts, go see a doctor\n",
        "\n",
        "    Keyword Arguments:\n",
        "        model_path {str} -- Similarity embedding model path (default: {'models/bertffn_crossentropy/bertffn'})\n",
        "        data_path {str} -- CSV data path (default: {'data/mqa_csv'})\n",
        "        output_path {str} -- Embedding output path (default: {'qa_embeddings/bertffn_crossentropy.zip'})\n",
        "        pretrained_path {str} -- Pretrained BioBert model path (default: {'models/pubmed_pmc_470k/'})\n",
        "    \"\"\"\n",
        "    if os.path.basename(model_path) == 'ffn':\n",
        "        ffn_weight_file = model_path\n",
        "    else:\n",
        "        ffn_weight_file = None\n",
        "\n",
        "    if os.path.basename(model_path) == 'bertffn':\n",
        "        bert_ffn_weight_file = model_path\n",
        "    else:\n",
        "        bert_ffn_weight_file = None\n",
        "    embeder = QAEmbed(\n",
        "        pretrained_path=pretrained_path,\n",
        "        ffn_weight_file=ffn_weight_file,\n",
        "        bert_ffn_weight_file=bert_ffn_weight_file\n",
        "    )\n",
        "    qa_df = read_all(data_path)\n",
        "    qa_df.dropna(inplace=True)\n",
        "    qa_vectors = embeder.predict(\n",
        "        questions=qa_df.question.tolist(),\n",
        "        answers=qa_df.answer.tolist())\n",
        "\n",
        "    q_embedding, a_embedding = np.split(qa_vectors, 2, axis=1)\n",
        "    qa_df['Q_FFNN_embeds'] = np.squeeze(q_embedding).tolist()\n",
        "    qa_df['A_FFNN_embeds'] = np.squeeze(a_embedding).tolist()\n",
        "    os.makedirs(os.path.dirname(output_path), exist_ok=True)\n",
        "    qa_df.to_parquet(output_path, index=False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5O1wMrbh624i",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_data_to_embedding(model_path=model_path,\n",
        "                            data_path=data_path,\n",
        "                            output_path=output_path,\n",
        "                            pretrained_path=pretrained_path)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "whrAoZVfGpLr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9QmjT3Mpn-FV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}